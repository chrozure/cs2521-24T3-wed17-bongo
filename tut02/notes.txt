Hello again and welcome to week 2!

In this tutorial we will be looking at:
    - Recursion
    - Analysis of Algorithms

Admin stuff:
    - This code is available on a Github repository
    - You can get lab01 handmarked today or next week
    - This week's lab has no handmarking (fully automarked)







So, what is recursion?
    - Recursion is a way of solving problems where a problem is solved by
        solving a small part of it, and then leaving the rest of it
        as a (almost) identical subproblem

We have a problem: we need to climb the rainbow stairs
    - Iterative:
        while i am not at the top:
            climb one step

    - Recursively:
        (base case)
        if i am at the top:
            do nothing, because I am at the top!

        (recursive case)
        else:
            climb one step, and then climb the rest of the staircase



Why should we use recursion?
    - It can make our code look a lot simpler
    - Some problems are easier to think about recursively
    - Some programming languages do not have loops (you have to use recursion!)


Downsides of recursion:
    - Could go on forever (stack overflow)
    - Takes up more memory
    - Slower than an iterative solution

    fib(5) = fib(4) + fib(3)
    fib(4) = fib(3) + fib(2)


Linked lists and recurstion:
    - You can think of a linked list as either:
        - An empty list (NULL)
        - A node, and the rest of the list










Analysis of algorithms
What is big-O?
    - A way of quantitatively describing how fast or slow an algorithm runs at scale

How do we calculate it?
    - e.g. T(n) = 2n(n + 3log(n))

    1. Remove the coefficients
    2n(n + 3log(n)) = 2n^2 + 6 * n log(n)
    -> n^2 + n log (n)

    2. Take the most dominant term
    -> O(n^2)
